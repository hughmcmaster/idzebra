<chapter id="examples">
 <!-- $Id: examples.xml,v 1.13 2002-10-18 16:16:59 mike Exp $ -->
 <title>Example Configurations</title>

 <sect1>
  <title>Overview</title>

  <para>
   <literal>zebraidx</literal> and <literal>zebrasrv</literal> are both
   driven by a master configuration file, which may refer to other
   subsidiary configuration files.  By default, they try to use
   <filename>zebra.cfg</filename> in the working directory as the
   master file; but this can be changed using the <literal>-t</literal>
   option to specify an alternative master configuration file.
  </para>
  <para>
   The master configuration file tells Zebra:
   <itemizedlist>

    <listitem>
     <para>
      Where to find subsidiary configuration files, including
      <literal>default.idx</literal>
      which specifies the default indexing rules.
     </para>
    </listitem>

    <listitem>
     <para>
      What attribute sets to recognise in searches.
     </para>
    </listitem>

    <listitem>
     <para>
      Policy details such as what record type to expect, what
      low-level indexing algorithm to use, how to identify potential
      duplicate records, etc.
     </para>
    </listitem>

   </itemizedlist>
  </para>
  <para>
   Now let's see what goes in the <literal>zebra.cfg</literal> file
   for some example configurations.
  </para>
 </sect1>

 <sect1 id="example1">
  <title>Example 1: XML Indexing And Searching</title>

  <para>
   This example shows how Zebra can be used with absolutely minimal
   configuration to index a body of
   <ulink url="http://www.w3.org/xml/###">XML</ulink>
   documents, and search them using
   <ulink url="http://www.w3.org/xpath/###">XPath</ulink>
   expressions to specify access points.
  </para>
  <para>
   Go to the <literal>examples/dinosauricon</literal> subdirectory
   of the distribution archive.
   There you will find a <literal>records</literal> subdirectory,
   which contains some raw XML data to be added to the database: in
   this case, as single file, <literal>genera.xml</literal>,
   which contain information about all the known dinosaur genera as of
   August 2002.
  </para>
  <para>
   Now we need to create the Zebra database, which we do with the
   Zebra indexer, <literal>zebraidx</literal>, which is
   driven by the <literal>zebra.cfg</literal> configuration file.
   For our purposes, we don't need any
   special behaviour - we can use the defaults - so we start with a
   minimal file that just tells <literal>zebraidx</literal> where to
   find the default indexing rules, and how to parse the records:
   <screen>
    profilePath: .:../../tab:../../../yaz/tab
    recordType: grs.sgml
   </screen>
  </para>
  <para>
   That's all you need for a minimal Zebra configuration.  Now you can
   roll the XML records into the database and build the indexes:
   <screen>
    zebraidx update records
   </screen>
  </para>
  <para>
   Now start the server.  Like the indexer, its behaviour is
   controlled by the
   <literal>zebra.cfg</literal> file; and like the indexer, it works
   just fine with this minimal configuration.
   <screen>
	zebrasrv
   </screen>
   By default, the server listens on IP port number 9999, although
   this can easily be changed - see 
   <xref linkend="zebrasrv"/>.
  </para>
  <para>
   Now you can use the Z39.50 client program of your choice to execute
   XPath-based boolean queries and fetch the XML records that satisfy
   them:
   <screen>
    $ yaz-client tcp:@:9999
    Connecting...Ok.
    Z&gt; find @attr 1=/GENUS/SPECIES/AUTHOR/@name Wedel
    Number of hits: 1
    Z&gt; format xml
    Z&gt; show 1
    &lt;GENUS name="Sauroposeidon" type="with"&gt;
     &lt;MEANING&gt;lizard Poseidon &lt;LOW&gt;(Greek god of, among other things, earthquakes)&lt;/LOW&gt;&lt;/MEANING&gt;
     &lt;SPECIES name="proteles"&gt;
      &lt;AUTHOR type="vide" name="Franklin" year="2000"&gt;&lt;/AUTHOR&gt;
      &lt;AUTHOR name="Wedel, Cifelli, Sanders"&gt;&lt;/AUTHOR&gt;
     &lt;/SPECIES&gt;
     &lt;PLACE name="Oklahoma"&gt;&lt;/PLACE&gt;
     &lt;TIME value="Albian"&gt;&lt;/TIME&gt;
     &lt;LENGTH value="30" q="1"&gt;&lt;/LENGTH&gt;
     &lt;REMAINS content="rib, cervical vertebrae"&gt;&lt;/REMAINS&gt;
     &lt;ESSAY&gt;
      &lt;P&gt; This new &lt;NOMEN name="Brachiosaurus"&gt;&lt;/NOMEN&gt;-like &lt;LINK content="dinosaur"&gt;&lt;/LINK&gt;
      was perhaps the tallest. With its head raised, it stood 60 feet (nearly
      20 m) tall. &lt;/P&gt;
     &lt;/ESSAY&gt;

      &lt;idzebra xmlns="http://www.indexdata.dk/zebra/"&gt;
	&lt;size&gt;593&lt;/size&gt;
	&lt;localnumber&gt;891&lt;/localnumber&gt;
	&lt;filename&gt;records/genera.xml&lt;/filename&gt;
      &lt;/idzebra&gt;
    &lt;/GENUS&gt;
   </screen>
  </para>
  <para>
   Now wasn't that easy?
  </para>
 </sect1>


 <sect1 id="example2">
  <title>Example 2: Supporting Interoperable Searches</title>

  <para>
   The problem with the previous example is that you need to know the
   structure of the documents in order to find them.  For example,
   when we wanted to know the genera for which Matt Wedel is an
   author
   (<foreignphrase role="taxon">Sauroposeidon proteles</foreignphrase>),
   we had to formulate a complex XPath 
   <literal>1=/GENUS/SPECIES/AUTHOR/@name</literal>
   which embodies the knowledge that author names are specified in the
   <literal>name</literal> attribute of the
   <literal>&lt;AUTHOR&gt;</literal> element,
   which is inside the
   <literal>&lt;SPECIES&gt;</literal> element,
   which in turn is inside the top-level
   <literal>&lt;GENUS&gt;</literal> element.
  </para>
  <para>
   This is bad not just because it requires a lot of typing, but more
   significantly because it ties searching semantics to the physical
   structure of the searched records.  You can't use the same search
   specification to search two databases if their internal
   representations are different.  Consider an alternative dinosaur
   database in which the records have author names specified
   inside an <literal>&lt;authorName&gt;</literal> element directly
   inside a top-level <literal>&lt;taxon&gt;</literal> element: then
   you'd need to search for them using
   <literal>1=/taxon/authorName</literal>
  </para>
  <para>
   How, then, can we build broadcasting Information Retrieval
   applications that look for records in many different databases?
   The Z39.50 protocol offers a powerful and general solution to this:
   abstract ``access points''.  In the Z39.50 model, an access point
   is simply a point at which searches can be directed.  Nothing is
   said about implementation: in a given database, an access point
   might be implemented as an index, a path into physical records, an
   algorithm for interrogating relational tables or whatever works.
   The key point is that the semantics of an access point are fixed
   and well defined.
  </para>
  <para>
   For convenience, access points are gathered into <firstterm>attribute
   sets</firstterm>.  For example, the BIB-1 attribute set is supposed to
   contain bibliographic access points such as author, title, subject
   and ISBN; the GEO attribute set contains access points pertaining
   to geospatial information (bounding box, ###, etc.); the CIMI
   attribute set contains access points to do with museum collections
   (provenance, inscriptions, etc.)
  </para>
  <para>
   In practice, the BIB-1 attribute set has tended to be a dumping
   ground for all sorts of access points, so that, for example, it
   includes some geospatial access points as well as strictly
   bibliographic ones.  Nevertheless, the key point is that this model
   allows a layer of abstraction over the physical representation of
   records in databases.
  </para>
  <para>
   In the BIB-1 attribute set, an author search is represented by
   access point 1003.  (See
   <ulink url="###bib1-semantics"/>)
   So we need to configure our dinosaur database so that searches for
   BIB-1 access point 1003 look the 
   <literal>name</literal> attribute of the
   <literal>&lt;AUTHOR&gt;</literal> element,
   inside the
   <literal>&lt;SPECIES&gt;</literal> element,
   inside the top-level
   <literal>&lt;GENUS&gt;</literal> element.
  </para>
  <para>
   This is a two-step process.  First, we need to tell Zebra that we
   want to support the BIB-1 attribute set.  Then we need to tell it
   which elements of its record pertain to access point 1003.
  </para>
  <para>
   We need to create an <link linkend="abs-file">Abstract Syntax
   file</link> named after the document element of the records we're
   working with, plus a <literal>.abs</literal> suffix - in this case,
   <literal>GENUS.abs</literal> - as follows:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     
    </para>
   </listitem>
   <listitem>
    <para>
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>


<!--
	The simplest hello-world example could go like this:
	
	Index the document
	
	<book>
	   <title>The art of motorcycle maintenance</title>
	   <subject scheme="Dewey">zen</subject>
	</book>
	
	And search it like
	
	f @attr 1=/book/title motorcycle
	
	f @attr 1=/book/subject[@scheme=Dewey] zen
	
	If you suddenly decide you want broader interop, you can add
	an abs file (more or less like this):
	
	attset bib1.att
	tagset tagsetg.tag
	
	elm (2,1)       title   title
	elm (2,21)      subject  subject
-->

<!--
How to include images:

	<mediaobject>
	  <imageobject>
	    <imagedata fileref="system.eps" format="eps">
	  </imageobject>
	  <imageobject>
	    <imagedata fileref="system.gif" format="gif">
	  </imageobject>
	  <textobject>
	    <phrase>The Multi-Lingual Search System Architecture</phrase>
	  </textobject>
	  <caption>
	    <para>
	      <emphasis role="strong">
		The Multi-Lingual Search System Architecture.
	      </emphasis>
	      <para>
		Network connections across local area networks are
		represented by straight lines, and those over the
		internet by jagged lines.
	  </caption>
	</mediaobject>

Where the three <*object> thingies inside the top-level <mediaobject>
are decreasingly preferred version to include depending on what the
rendering engine can handle.  I generated the EPS version of the image
by exporting a line-drawing done in TGIF, then converted that to the
GIF using a shell-script called "epstogif" which used an appallingly
baroque sequence of conversions, which I would prefer not to pollute
the Zebra build environment with:

	#!/bin/sh

	# Yes, what follows is stupidly convoluted, but I can't find a
	# more straightforward path from the EPS generated by tgif's
	# "Print" command into a browser-friendly format.

	file=`echo "$1" | sed 's/\.eps//'`
	ps2pdf "$1" "$file".pdf
	pdftopbm "$file".pdf "$file"
	pnmscale 0.50 < "$file"-000001.pbm | pnmcrop | ppmtogif
	rm -f "$file".pdf "$file"-000001.pbm

-->

 <!-- Keep this comment at the end of the file
 Local variables:
 mode: sgml
 sgml-omittag:t
 sgml-shorttag:t
 sgml-minimize-attributes:nil
 sgml-always-quote-attributes:t
 sgml-indent-step:1
 sgml-indent-data:t
 sgml-parent-document: "zebra.xml"
 sgml-local-catalogs: nil
 sgml-namecase-general:t
 End:
 -->
